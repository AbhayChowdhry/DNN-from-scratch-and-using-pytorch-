{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n78PsmMezjxn",
        "outputId": "7c6920c5-bad9-4ea6-cc2c-626281f1b662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: idx2numpy in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision\n",
        "\n",
        "!pip install idx2numpy\n",
        "\n",
        "import idx2numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmKndFvLrvm1",
        "outputId": "c7d4a4a2-0bd3-4ddf-99e9-8e73158b0e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MNIST\n",
            "--2024-02-01 18:02:23--  https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)... 54.231.234.81, 54.231.204.57, 52.217.165.193, ...\n",
            "Connecting to ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)|54.231.234.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]   9.45M  4.86MB/s    in 1.9s    \n",
            "\n",
            "2024-02-01 18:02:26 (4.86 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2024-02-01 18:02:26--  https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)... 54.231.234.81, 54.231.204.57, 52.217.165.193, ...\n",
            "Connecting to ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)|54.231.234.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.20K   131KB/s    in 0.2s    \n",
            "\n",
            "2024-02-01 18:02:27 (131 KB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2024-02-01 18:02:27--  https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)... 54.231.234.81, 54.231.204.57, 52.217.165.193, ...\n",
            "Connecting to ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)|54.231.234.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   1.57M  1.22MB/s    in 1.3s    \n",
            "\n",
            "2024-02-01 18:02:30 (1.22 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2024-02-01 18:02:30--  https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)... 16.182.107.57, 16.182.40.185, 52.216.184.51, ...\n",
            "Connecting to ossci-datasets.s3.amazonaws.com (ossci-datasets.s3.amazonaws.com)|16.182.107.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-01 18:02:31 (236 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!rm -rf MNIST\n",
        "!mkdir MNIST\n",
        "%cd MNIST\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "!gunzip /content/MNIST/train-images-idx3-ubyte.gz\n",
        "!gunzip /content/MNIST/train-labels-idx1-ubyte.gz\n",
        "!gunzip /content/MNIST/t10k-images-idx3-ubyte.gz\n",
        "!gunzip /content/MNIST/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "m_NmpAK-zjxo"
      },
      "outputs": [],
      "source": [
        "class custom_dataset:\n",
        "    def __init__(self, transform=None, train=True):\n",
        "        # define data, target and transform\n",
        "        mnist_folder_path = os.path.join(os.getcwd(), 'MNIST')\n",
        "\n",
        "        train_images_file = os.path.join(mnist_folder_path, 'train-images-idx3-ubyte')\n",
        "        train_labels_folder = os.path.join(mnist_folder_path, 'train-labels-idx1-ubyte')\n",
        "        test_images_folder = os.path.join(mnist_folder_path, 't10k-images-idx3-ubyte')\n",
        "        test_labels_folder = os.path.join(mnist_folder_path, 't10k-labels-idx1-ubyte')\n",
        "\n",
        "        train_images = idx2numpy.convert_from_file(train_images_file)\n",
        "        train_labels = idx2numpy.convert_from_file(train_labels_folder)\n",
        "        test_images = idx2numpy.convert_from_file(test_images_folder)\n",
        "        test_labels = idx2numpy.convert_from_file(test_labels_folder)\n",
        "\n",
        "        train_images = train_images / 255\n",
        "        test_images = test_images / 255\n",
        "\n",
        "        self.train_data = train_images\n",
        "        self.train_target = train_labels\n",
        "        self.test_data = test_images\n",
        "        self.test_target = test_labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "\n",
        "        if self.train == True:\n",
        "            img, target = self.train_data[index], int(self.train_target[index])\n",
        "\n",
        "        else:\n",
        "            img, target = self.test_data[index], int(self.test_target[index])\n",
        "\n",
        "        if self.transform == \"Normalize\":\n",
        "            img = (img - img.mean()) / img.std()\n",
        "        elif self.transform == \"ToTensor\":\n",
        "            img = torch.from_numpy(img)\n",
        "        elif self.transform == \"None\":\n",
        "            img = img\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.train_data)\n",
        "\n",
        "class CustomDataLoader:\n",
        "    def __init__(self, data, batch_size, shuffle=False):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.current_index = 0\n",
        "        self.indices = list(range(len(self.data)))\n",
        "\n",
        "        if self.shuffle:\n",
        "            self._shuffle_data()\n",
        "\n",
        "    def _shuffle_data(self):\n",
        "        random.shuffle(self.indices)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current_index >= len(self.data):\n",
        "            raise StopIteration\n",
        "\n",
        "        batch_indices = self.indices[self.current_index:self.current_index + self.batch_size]\n",
        "        batch = [self.data[i] for i in batch_indices]\n",
        "\n",
        "        self.current_index += self.batch_size\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "i4TEHFh8zjxp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "batch_size = [128, 256, 512, 1024]\n",
        "times_custom = []\n",
        "times_pytorch = []\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "for batch in batch_size:\n",
        "\n",
        "    time_custom = 0\n",
        "    time_pytorch = 0\n",
        "\n",
        "    # download and load training dataset\n",
        "    st = time.time()\n",
        "    pytorch_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    pytorch_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    en = time.time()\n",
        "    time_pytorch += en - st\n",
        "\n",
        "    # download and load training dataset\n",
        "    st = time.time()\n",
        "    custom_train = custom_dataset(train=True, transform=\"Normalize\")\n",
        "    custom_test = custom_dataset(train=False, transform=\"Normalize\")\n",
        "    en = time.time()\n",
        "    time_custom += en - st\n",
        "\n",
        "    # custom loader\n",
        "    st = time.time()\n",
        "    custom_trainloader = CustomDataLoader(pytorch_train, batch_size=batch, shuffle=True)\n",
        "    custom_testloader = CustomDataLoader(pytorch_test, batch_size=batch, shuffle=True)\n",
        "    en = time.time()\n",
        "    time_custom += en - st\n",
        "\n",
        "    # pytorch loader\n",
        "    st = time.time()\n",
        "    pytorch_trainloader = torch.utils.data.DataLoader(pytorch_train, batch_size=batch, shuffle=True)\n",
        "    pytorch_testloader = torch.utils.data.DataLoader(pytorch_test, batch_size=batch, shuffle=True)\n",
        "    en = time.time()\n",
        "    time_pytorch += en - st\n",
        "\n",
        "    times_custom.append(time_custom)\n",
        "    times_pytorch.append(time_pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "dBe2xVH9zjxq",
        "outputId": "30f4ab42-a93f-4b60-f259-101b50768a66"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(batch_size, times_custom, label=\"custom\")\n",
        "plt.plot(batch_size, times_pytorch, label=\"pytorch\")\n",
        "plt.xlabel(\"batch size\")\n",
        "plt.ylabel(\"time\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Kd1YEkzszjxq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Hq92G445zjxq"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, 256)\n",
        "        self.layer2 = nn.Linear(256, 128)\n",
        "        self.layer3 = nn.Linear(128, 64)\n",
        "        self.layer4 = nn.Linear(64, 32)\n",
        "        self.layer5 = nn.Linear(32, num_classes)\n",
        "        # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.relu(self.layer3(x))\n",
        "        x = F.relu(self.layer4(x))\n",
        "        x = F.relu(self.layer5(x))\n",
        "        # x = self.softmax(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA9bWsAbzjxq",
        "outputId": "6e4c68dc-0d50-43c2-f5d1-d05732c5006d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = NN(784, 10).to(device)\n",
        "learning_rate = 0.0003\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "cnF5fZXOzjxr"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Lambda\n",
        "\n",
        "class CustomTransform:\n",
        "    def __call__(self, img):\n",
        "        return img*255\n",
        "\n",
        "CustomTransform = CustomTransform()\n",
        "transform_list = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    CustomTransform,\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root='/dataset', train=True, transform=transform_list, download=True)\n",
        "trainloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(train_data, [53000, 7000])\n",
        "valloader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root='/dataset', train=False, transform=transform_list, download=True)\n",
        "testloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN6uriB_zjxr",
        "outputId": "70c0f1ec-01c4-48be-862d-2b5e80a1b3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Train Loss: 1.2307, Train Acc: 0.6164, Test Loss: 0.8351, Test Acc: 0.7610\n",
            "Epoch 1, Train Loss: 0.7869, Train Acc: 0.7866, Test Loss: 0.7224, Test Acc: 0.8092\n",
            "Epoch 2, Train Loss: 0.7146, Train Acc: 0.8145, Test Loss: 0.6799, Test Acc: 0.8258\n",
            "Epoch 3, Train Loss: 0.6776, Train Acc: 0.8276, Test Loss: 0.6598, Test Acc: 0.8345\n",
            "Epoch 4, Train Loss: 0.6532, Train Acc: 0.8356, Test Loss: 0.6388, Test Acc: 0.8389\n",
            "Epoch 5, Train Loss: 0.6349, Train Acc: 0.8422, Test Loss: 0.6228, Test Acc: 0.8460\n",
            "Epoch 6, Train Loss: 0.6202, Train Acc: 0.8467, Test Loss: 0.6134, Test Acc: 0.8491\n",
            "Epoch 7, Train Loss: 0.6080, Train Acc: 0.8501, Test Loss: 0.6045, Test Acc: 0.8496\n",
            "Epoch 8, Train Loss: 0.5975, Train Acc: 0.8540, Test Loss: 0.5964, Test Acc: 0.8555\n",
            "Epoch 9, Train Loss: 0.5891, Train Acc: 0.8567, Test Loss: 0.5912, Test Acc: 0.8547\n",
            "Epoch 10, Train Loss: 0.5812, Train Acc: 0.8591, Test Loss: 0.5855, Test Acc: 0.8582\n",
            "Epoch 11, Train Loss: 0.5748, Train Acc: 0.8618, Test Loss: 0.5821, Test Acc: 0.8580\n",
            "Epoch 12, Train Loss: 0.5686, Train Acc: 0.8634, Test Loss: 0.5791, Test Acc: 0.8599\n",
            "Epoch 13, Train Loss: 0.5635, Train Acc: 0.8657, Test Loss: 0.5757, Test Acc: 0.8606\n",
            "Epoch 14, Train Loss: 0.5585, Train Acc: 0.8670, Test Loss: 0.5713, Test Acc: 0.8617\n",
            "Epoch 15, Train Loss: 0.5541, Train Acc: 0.8683, Test Loss: 0.5693, Test Acc: 0.8619\n",
            "Epoch 16, Train Loss: 0.5497, Train Acc: 0.8692, Test Loss: 0.5694, Test Acc: 0.8630\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define lists to store training, validation, and testing loss and accuracy\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "num_epochs = 60  # You can set the number of epochs as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    model.train()\n",
        "    for idx, (images, labels) in enumerate(trainloader):\n",
        "\n",
        "        images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        score = model(images)\n",
        "        loss = criterion(score, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        correct += (torch.argmax(score, dim=1) == labels).sum().item()\n",
        "\n",
        "    train_acc = correct / len(train_data)\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_loss_list.append(train_loss)\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in enumerate(testloader):\n",
        "\n",
        "            images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            score = model(images)\n",
        "            loss = criterion(score, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            correct += (torch.argmax(score, dim=1) == labels).sum().item()\n",
        "\n",
        "    test_acc = correct / len(test_data)\n",
        "    test_loss = test_loss / len(testloader)\n",
        "    test_loss_list.append(test_loss)\n",
        "    test_acc_list.append(test_acc)\n",
        "\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in enumerate(valloader):\n",
        "\n",
        "            images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            score = model(images)\n",
        "            loss = criterion(score, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            correct += (torch.argmax(score, dim=1) == labels).sum().item()\n",
        "\n",
        "    val_acc = correct / len(val_data)\n",
        "    val_loss = val_loss / len(valloader)\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, '\n",
        "            f'Training Loss: {train_loss:.4f}, '\n",
        "            f'Testing Loss: {test_loss:.4f}, '\n",
        "            f'Validation Loss: {val_loss:.4f}, '\n",
        "            f'Training Accuracy: {train_acc:.4f}, '\n",
        "            f'Testing Accuracy: {test_acc:.4f}, '\n",
        "            f'Validation Accuracy: {val_acc:.4f}')    \n",
        "\n",
        "# Plot the training loss and accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_list, label='Training Loss')\n",
        "plt.plot(test_loss_list, label='Testing Loss')\n",
        "plt.plot(val_loss_list, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_acc_list, label='Training Accuracy')\n",
        "plt.plot(test_acc_list, label='Testing Accuracy')\n",
        "plt.plot(val_acc_list, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMratrpezjxr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q41UxDcgzjxs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bT2g1LP1zjxs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NTyK59shzjxs"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, N, A, lr, act_func, epochs, batchsize):\n",
        "        self.N = N + 2 \n",
        "        self.A = A\n",
        "        self.lr = lr\n",
        "        self.act_func = act_func\n",
        "        self.epochs = epochs\n",
        "        self.batchsize = batchsize\n",
        "        self.loss = []\n",
        "        self.train_acc = []\n",
        "        self.wts = []\n",
        "        self.biases = []\n",
        "        self.val_loss = []\n",
        "        self.val_acc = []\n",
        "        self.test_loss = []\n",
        "        self.test_acc = []\n",
        "\n",
        "    def softmax(self, z):\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
        "\n",
        "    def softmax_grad(self, z):\n",
        "        return self.softmax(z) * (1 - self.softmax(z))\n",
        "\n",
        "    def cross_entropy_loss(self, predictions, true_labels):\n",
        "        \n",
        "        epsilon = 1e-15  # Small constant to avoid taking the logarithm of zero\n",
        "    \n",
        "        # Clip predictions to avoid log(0)\n",
        "        predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
        "        \n",
        "        # Add a small constant to avoid log(0)\n",
        "        predictions = np.maximum(predictions, epsilon)\n",
        "        \n",
        "        # Calculate cross-entropy loss\n",
        "        loss = -np.sum(true_labels * np.log(predictions)) / len(predictions)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def activation(self, z):\n",
        "\n",
        "        if self.act_func == 'sigmoid':\n",
        "            return 1 / (1 + np.exp(-z + 1e-8))\n",
        "        elif self.act_func == 'relu':\n",
        "            return np.maximum(0, z)\n",
        "        elif self.act_func == 'softmax':\n",
        "            return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
        "\n",
        "    def activation_grad(self, z):\n",
        "\n",
        "        if self.act_func == 'sigmoid':\n",
        "            return self.activation(z) * (1 - self.activation(z))\n",
        "        elif self.act_func == 'relu':\n",
        "            return np.where(z > 0, 1, 0)\n",
        "        elif self.act_func == 'softmax':\n",
        "            return self.activation(z) * (1 - self.activation(z))\n",
        "\n",
        "    def val_data(self, X_val, y_val):\n",
        "        a = [X_val]\n",
        "        for j in range(len(self.A) - 1):\n",
        "            a.append(self.activation(np.dot(a[j], self.wts[j]) + self.biases[j]))\n",
        "\n",
        "        a[-1] = self.softmax(a[-1])\n",
        "\n",
        "        loss = self.cross_entropy_loss(a[-1], y_val)\n",
        "\n",
        "        self.val_loss.append(loss)\n",
        "        self.val_acc.append(self.accuracy(np.argmax(y_val, axis=1), np.argmax(a[-1], axis=1)))\n",
        "\n",
        "    def test_data(self, X_test, y_test):\n",
        "        a = [X_test]\n",
        "        for j in range(len(self.A) - 1):\n",
        "            a.append(self.activation(np.dot(a[j], self.wts[j]) + self.biases[j]))\n",
        "\n",
        "        a[-1] = self.softmax(a[-1])\n",
        "\n",
        "        loss = self.cross_entropy_loss(a[-1], y_test)\n",
        "\n",
        "        self.test_loss.append(loss)\n",
        "        self.test_acc = self.accuracy(np.argmax(y_test, axis=1), np.argmax(a[-1], axis=1))\n",
        "\n",
        "\n",
        "    def fit(self, X, y, X_val, y_val, X_test, y_test):\n",
        "        self.A.insert(0, X.shape[1])\n",
        "        self.A.append(10)\n",
        "\n",
        "        # for i in range(len(self.A) - 1):\n",
        "        #     # random between 0 and 1\n",
        "        #     self.wts.append(np.random.rand(self.A[i], self.A[i + 1]))\n",
        "        #     self.biases.append(np.random.rand(1, self.A[i + 1]))\n",
        "\n",
        "        # Xavier Initialization\n",
        "        for i in range(len(self.A) - 1):\n",
        "            self.wts.append(np.random.randn(self.A[i], self.A[i + 1]) * np.sqrt(1 / self.A[i]))\n",
        "            self.biases.append(np.random.randn(1, self.A[i + 1]) * np.sqrt(1 / self.A[i]))\n",
        "\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(0, X.shape[0], self.batchsize):\n",
        "                X_batch = X[i:i + self.batchsize]\n",
        "                y_batch = y[i:i + self.batchsize]\n",
        "\n",
        "                a = [X_batch]\n",
        "\n",
        "                \n",
        "                for j in range(len(self.A) - 1):\n",
        "                    a.append(self.activation(np.dot(a[j], self.wts[j]) + self.biases[j]))\n",
        "\n",
        "                # print(\"Activations:\")\n",
        "                # print(a)\n",
        "                # print()\n",
        "                # print(\"Weights:\")\n",
        "                # print(self.wts)\n",
        "                # print()\n",
        "                # print(\"Biases:\")\n",
        "                # print(self.biases)\n",
        "                # print()\n",
        "\n",
        "                # print(\"A ki shape is\", a[-1].shape)\n",
        "                # print(\"Labels ki shape is\", y_batch.shape)\n",
        "\n",
        "                # print(a[-1][0])\n",
        "                # print(y_batch[0])\n",
        "                \n",
        "                a[-1] = self.softmax(a[-1])\n",
        "\n",
        "                loss = self.cross_entropy_loss(a[-1], y_batch)\n",
        "\n",
        "                # print(loss)\n",
        "\n",
        "\n",
        "                delta = (a[-1] - y_batch) / self.batchsize\n",
        "\n",
        "                for j in range(len(self.A) - 1, 0, -1):\n",
        "                    self.wts[j - 1] -= self.lr * np.dot(a[j - 1].T, delta)\n",
        "                    self.biases[j - 1] -= self.lr * np.sum(delta, axis=0)\n",
        "\n",
        "                    delta = np.dot(delta, self.wts[j - 1].T) * self.activation_grad(a[j - 1])\n",
        "\n",
        "            self.loss.append(loss)\n",
        "            self.train_acc.append(self.accuracy(np.argmax(y_batch, axis=1), np.argmax(a[-1], axis=1)))\n",
        "            self.val_data(X_val, y_val)\n",
        "            self.test_data(X_test, y_test)\n",
        "            print('Epoch:', epoch + 1, '/', self.epochs, 'Loss:', loss)\n",
        "\n",
        "    def predict(self, X):\n",
        "        a = [X]\n",
        "        for j in range(len(self.A) - 1):\n",
        "            a.append(self.activation(np.dot(a[j], self.wts[j]) + self.biases[j]))\n",
        "\n",
        "        a[-1] = self.softmax(a[-1])\n",
        "\n",
        "        return a[-1]\n",
        "\n",
        "    def plot_loss(self):\n",
        "        plt.plot(self.loss)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "\n",
        "    def accuracy(self, y_true, y_pred):\n",
        "        return np.mean(y_true == y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MNIST dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "X_train = trainset.data\n",
        "y_train = trainset.targets\n",
        "\n",
        "X_test = testset.data\n",
        "y_test = testset.targets\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], -1).numpy()\n",
        "X_test = X_test.reshape(X_test.shape[0], -1).numpy()\n",
        "\n",
        "y_train = y_train.numpy()\n",
        "y_test = y_test.numpy()\n",
        "\n",
        "enc = OneHotEncoder()\n",
        "y_train = enc.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# validation set is 10% of the training set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_Nu-fF0bzjxt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Epoch: 1 / 60 Loss: 2.266064044816046\n",
            "Epoch: 2 / 60 Loss: 2.2412538319424518\n",
            "Epoch: 3 / 60 Loss: 2.1966829314741836\n",
            "Epoch: 4 / 60 Loss: 2.1249951211135043\n",
            "Epoch: 5 / 60 Loss: 2.0249141992511692\n",
            "Epoch: 6 / 60 Loss: 1.868104539345968\n",
            "Epoch: 7 / 60 Loss: 1.6543661878265539\n",
            "Epoch: 8 / 60 Loss: 1.4900625661083327\n",
            "Epoch: 9 / 60 Loss: 1.3400556422571952\n",
            "Epoch: 10 / 60 Loss: 1.2078691926145793\n",
            "Epoch: 11 / 60 Loss: 1.0765023433723135\n",
            "Epoch: 12 / 60 Loss: 0.9503657562511586\n",
            "Epoch: 13 / 60 Loss: 0.8415899378134308\n",
            "Epoch: 14 / 60 Loss: 0.7476166160666142\n",
            "Epoch: 15 / 60 Loss: 0.6719456718323051\n",
            "Epoch: 16 / 60 Loss: 0.6148856994616548\n",
            "Epoch: 17 / 60 Loss: 0.5700816267985003\n",
            "Epoch: 18 / 60 Loss: 0.5296880388710827\n",
            "Epoch: 19 / 60 Loss: 0.498724921147492\n",
            "Epoch: 20 / 60 Loss: 0.47338086040913957\n",
            "Epoch: 21 / 60 Loss: 0.4537415871584518\n",
            "Epoch: 22 / 60 Loss: 0.43850650856029416\n",
            "Epoch: 23 / 60 Loss: 0.4257948110572458\n",
            "Epoch: 24 / 60 Loss: 0.4148384964054557\n",
            "Epoch: 25 / 60 Loss: 0.4052104087951621\n",
            "Epoch: 26 / 60 Loss: 0.39701482038535996\n",
            "Epoch: 27 / 60 Loss: 0.3902112660927036\n",
            "Epoch: 28 / 60 Loss: 0.38441985578017057\n",
            "Epoch: 29 / 60 Loss: 0.3785043428778945\n",
            "Epoch: 30 / 60 Loss: 0.3722283619427602\n",
            "Epoch: 31 / 60 Loss: 0.3672088848474855\n",
            "Epoch: 32 / 60 Loss: 0.36179038846326184\n",
            "Epoch: 33 / 60 Loss: 0.3566016261077476\n",
            "Epoch: 34 / 60 Loss: 0.35226038576281443\n",
            "Epoch: 35 / 60 Loss: 0.34753326693657083\n",
            "Epoch: 36 / 60 Loss: 0.3432177700033169\n",
            "Epoch: 37 / 60 Loss: 0.3392086092568005\n",
            "Epoch: 38 / 60 Loss: 0.33548407218889564\n",
            "Epoch: 39 / 60 Loss: 0.33160239269789193\n",
            "Epoch: 40 / 60 Loss: 0.32818631154202427\n",
            "Epoch: 41 / 60 Loss: 0.32472440369846833\n",
            "Epoch: 42 / 60 Loss: 0.32111372218434564\n",
            "Epoch: 43 / 60 Loss: 0.31815504872114564\n",
            "Epoch: 44 / 60 Loss: 0.31521684209354073\n",
            "Epoch: 45 / 60 Loss: 0.3121973536456003\n",
            "Epoch: 46 / 60 Loss: 0.30949535889485735\n",
            "Epoch: 47 / 60 Loss: 0.3066532340801923\n",
            "Epoch: 48 / 60 Loss: 0.30371670138818263\n",
            "Epoch: 49 / 60 Loss: 0.30147102410981363\n",
            "Epoch: 50 / 60 Loss: 0.29897331648272973\n",
            "Epoch: 51 / 60 Loss: 0.2967027998568078\n",
            "Epoch: 52 / 60 Loss: 0.29446442974450526\n",
            "Epoch: 53 / 60 Loss: 0.2917543928027113\n",
            "Epoch: 54 / 60 Loss: 0.2894265644311814\n",
            "Epoch: 55 / 60 Loss: 0.2869406135056862\n",
            "Epoch: 56 / 60 Loss: 0.2848273020969532\n",
            "Epoch: 57 / 60 Loss: 0.28274570366268215\n",
            "Epoch: 58 / 60 Loss: 0.2809501899940934\n",
            "Epoch: 59 / 60 Loss: 0.2792941627374329\n",
            "Epoch: 60 / 60 Loss: 0.2775469682360877\n"
          ]
        }
      ],
      "source": [
        "nn = NeuralNetwork(N=4, A=[256, 128, 64, 32], lr=0.0003, act_func='relu', epochs=60, batchsize=32)\n",
        "nn.fit(X_train, y_train, X_val, y_val, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = np.argmax(nn.predict(X_test), axis=1)\n",
        "print(f'Accuracy: {nn.accuracy(np.argmax(y_test, axis=1), y_pred)}')\n",
        "\n",
        "# plot all loss and accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(nn.loss, label='Training Loss')\n",
        "plt.plot(nn.val_loss, label='Validation Loss')\n",
        "plt.plot(nn.test_loss, label='Testing Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(nn.train_acc, label='Training Accuracy')\n",
        "plt.plot(nn.val_acc, label='Validation Accuracy')\n",
        "plt.plot(nn.test_acc, label='Testing Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
